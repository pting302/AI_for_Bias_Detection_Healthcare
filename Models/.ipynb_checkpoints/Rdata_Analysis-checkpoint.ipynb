{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import imblearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import fastai\n",
    "from fastai import *\n",
    "import fastai.tabular.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../5v_cleandf.rdata'\n",
    "r_format = pyreadr.read_r(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_format.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r_format['df']\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially relevant columns here are `gender`, `ethnicity`, `race`, `employstatus`, `insurance_status`, `disposition`. The majority of the columns are categorical results of whether a patient has a condition or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='race', data=df)\n",
    "plt.title('Distribution of Races Within Dataset')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart(insurance_status, data, data2):\n",
    "    color_palette = {\n",
    "        'White or Caucasian': 'blue',\n",
    "        'Black or African American': 'orange',\n",
    "        'Other': 'green',\n",
    "        'Asian': 'red',\n",
    "        'Patient Refused': 'purple',\n",
    "        'Unknown': 'brown',\n",
    "        'American Indian or Alaska Native': 'pink',\n",
    "        'Native Hawaiian or Other Pacific Islander': 'gray',\n",
    "        np.nan: 'yellow'\n",
    "    } # set the color palette so that all plots have the same colors for the same race\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    def pie_subplot(data, row, col, which, title):\n",
    "        # get the subsection of the dataframe with that particular insurance status\n",
    "        data_with_insurance_status = data[data['insurance_status'] == insurance_status]\n",
    "        unique_races = data_with_insurance_status['race'].unique()\n",
    "\n",
    "        keys_data = []\n",
    "        for race in unique_races:\n",
    "            keys_data.append(\n",
    "                (\n",
    "                    race,\n",
    "                    data_with_insurance_status[data_with_insurance_status['race'] == race]['race']\n",
    "                        .count()\n",
    "                ) # append a particular race and the number of people with a particular insurance status\n",
    "            )\n",
    "\n",
    "        keys_data.sort(key=lambda x: x[1], reverse=True) # sort by the number of people\n",
    "\n",
    "        keys = [x[0] for x in keys_data]\n",
    "        values = [x[1] for x in keys_data]\n",
    "\n",
    "        colors = [color_palette[x] for x in keys]\n",
    "\n",
    "        # Plot a pie chart\n",
    "        plt.subplot(row, col, which)\n",
    "        plt.pie(values, colors=colors)\n",
    "        plt.legend(keys)\n",
    "        plt.title(title)\n",
    "\n",
    "    # data is a comprised of samples of 100 datapoints for each race because there aren't an\n",
    "    # equal amount of each race --> this is a way to show the real distribution\n",
    "    pie_subplot(data, 1, 2, 1, insurance_status)\n",
    "    # data2 is just the whole dataframe\n",
    "    pie_subplot(data2, 1, 2, 2, insurance_status + \" Real\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampled_df(df):\n",
    "    sample1 = df[df['race'] == 'White or Caucasian'].sample(n=100)\n",
    "    sample2 = df[df['race'] == 'Black or African American'].sample(n=100)\n",
    "    sample3 = df[df['race'] == 'Other'].sample(n=100)\n",
    "    sample4 = df[df['race'] == 'Asian'].sample(n=100)\n",
    "    sample5 = df[df['race'] == 'Patient Refused'].sample(n=100)\n",
    "    sample6 = df[df['race'] == 'Unknown'].sample(n=100)\n",
    "    sample7 = df[df['race'] == 'American Indian or Alaska Native'].sample(n=100)\n",
    "    sample8 = df[df['race'] == 'Native Hawaiian or Other Pacific Islander'].sample(n=100)\n",
    "\n",
    "    # Put the samples together into one dataframe for use\n",
    "    plot_df = pd.concat([sample1, sample2, sample3, sample4, sample5, sample6, sample7, sample8])\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = create_sampled_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Race Distributions of Insurance Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['insurance_status'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart('Commercial', plot_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart('Medicaid', plot_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart('Medicare', plot_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart('Other', plot_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart('Self pay', plot_df, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only notable thing I noticed was that despite its smaller population, a greater percentage of black people have Medicaid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['employstatus'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='employstatus', data=plot_df, hue='race')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Employment Status Random Sample')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='employstatus', data=df, hue='race')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Employment Status Full Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no blatant disparrities within the employment status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['disposition'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['previousdispo'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Race & Disposition on Full Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(contingency):\n",
    "    c, p_val, dof, expected = chi2_contingency(contingency)\n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df['race'], df['previousdispo'])\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contingency_pct = pd.crosstab(df['race'], df['previousdispo'], normalize='index')\n",
    "# contingency_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency, annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L&D -> Labor And Delivey\n",
    "* LWBS -> Left Without Being Seen By Physician\n",
    "* AMA -> Against Medical Service ??\n",
    "* Eloped -> Eloped During Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(contingency)\n",
    "#surface level stat analysis shows a correlation btw ethnicity and disposition within the hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Race & Disposition on Sampled Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(plot_df['race'], plot_df['previousdispo'])\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(contingency)\n",
    "#surface level stat analysis shows a correlation btw ethnicity and disposition within the hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Gender & Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df['gender'], df['previousdispo'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Age & Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.age.max(), df.age.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]\n",
    "labels = ['(0-10]', '(10-20]', '(20-30]', '(30-40]',\n",
    "          '(40-50]', '(50-60]', '(60-70]', '(70-80]', '(80-90]', '(90-100]', '(100-110]']\n",
    "\n",
    "df['age_groups'] = pd.cut(x=df['age'], bins=bins, labels=labels)\n",
    "df['age_groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df['age_groups'], df['previousdispo'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Race & Arrival Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df['race'], df['arrivalmode'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condensing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condense the large dataframe into another with only the necessary columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataframe have a significant member of **null** values; however, we still have enough data, that removing the rows with any null values will leave us with plenty of data. Therefore, instead of letting the nulls propogate to more refined versions of the dataset, we can remove them right here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a smaller dataframe with only the columns we care about, in order to condense the data and speed up operation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['esi',\n",
    "           'age',\n",
    "           'gender',\n",
    "           'ethnicity',\n",
    "           'race',\n",
    "           'lang',\n",
    "           'religion',\n",
    "           'maritalstatus',\n",
    "           'employstatus',\n",
    "           'insurance_status',\n",
    "           'disposition',\n",
    "           'arrivalmode',\n",
    "           'previousdispo']\n",
    "\n",
    "data = df.copy()[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with missing values for every column\n",
    "\n",
    "cols_in_dataframe = list(data.columns)\n",
    "\n",
    "for col in cols_in_dataframe:\n",
    "    rows_to_remove = []\n",
    "    nulled_col = list(data[col].isnull())\n",
    "    for i in range(len(nulled_col)):\n",
    "        if nulled_col[i] == True:\n",
    "            rows_to_remove.append(i)\n",
    "    rows_to_remove.sort(reverse=True)\n",
    "    \n",
    "    data.drop(rows_to_remove, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print('Done condensing:', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the rows with a **null** value in them are now removed from the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating An Averaged Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( number of samples, contingency variable 1, contingency variable 2, dataframe )\n",
    "def create_samples(num_samples, contv1, contv2, df):\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        plot_df = create_sampled_df(df)\n",
    "        contingency = pd.crosstab(plot_df[contv1], plot_df[contv2])\n",
    "\n",
    "        # find the columns that were not in the contingency table\n",
    "        # all the columns that are left over\n",
    "        left_over = list(set(df[contv2].unique()) - set(contingency.columns))\n",
    "        for col in left_over:\n",
    "            contingency[col] = [0 for _ in list(contingency.index)]\n",
    "\n",
    "        samples.append(contingency)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def create_average_contingency_table(samples):\n",
    "    samples_len = len(samples)\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    shapes = [x.shape for x in samples]\n",
    "    example_sample = samples[0]\n",
    "\n",
    "    for col in example_sample:\n",
    "        values = []\n",
    "        for sample in samples:\n",
    "            values.append(np.array(sample[col]))\n",
    "        values = np.array(values)\n",
    "        average_values = np.mean(values, axis=0)\n",
    "        main_df[col] = average_values\n",
    "\n",
    "    main_df = main_df.set_index(pd.Index(example_sample.index))\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = create_samples(100, 'race', 'previousdispo', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cont_table = create_average_contingency_table(samples)\n",
    "average_cont_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler = RandomOverSampler(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cont = ['esi', 'age']\n",
    "cat = [\n",
    "    'gender',\n",
    "    'ethnicity',\n",
    "    'race',\n",
    "    'lang',\n",
    "    'religion',\n",
    "    'maritalstatus',\n",
    "    'employstatus',\n",
    "    'insurance_status',\n",
    "    'disposition',\n",
    "    'arrivalmode',\n",
    "    'previousdispo'\n",
    "]\n",
    "\n",
    "# Create individual label encoders for each column\n",
    "transformers = {}\n",
    "for col in cat:\n",
    "    transformers[col] = LabelEncoder()\n",
    "\n",
    "# fit each column with its corresponding label encoder\n",
    "for col in cat:\n",
    "    data[col] = data[[col]].apply(transformers[col].fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['esi'] = data['esi'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_balance = 'race'\n",
    "cols_without_balancing_col = [\n",
    "    'esi',\n",
    "    'age',\n",
    "    'gender',\n",
    "    'ethnicity',\n",
    "    'lang',\n",
    "    'religion',\n",
    "    'maritalstatus',\n",
    "    'employstatus',\n",
    "    'insurance_status',\n",
    "    'disposition',\n",
    "    'arrivalmode',\n",
    "    'previousdispo'\n",
    "]\n",
    "\n",
    "X, y = data[cols_without_balancing_col].values, data[col_to_balance].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampler resamples the smallest member to the biggest member and this needs to be done a certain number of times to get an equal amount of each race within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the races are extremely small in propertion to other races. The operation above scales all the data from the races with the smallest dataset population to the races with the largest dataset population. This results in a lot of generated or repeated data, which might affect the quality of the models that this data can produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is now the number of samples for each race where the numbers `[0-7]` can be corresponded to a label encoded race. The race can be derived with `transformers['race'].inverse_transform([0, 1, 2, 3, 4, 5, 7, 7])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.DataFrame(X_resampled, columns=cols_without_balancing_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['race'] = y_resampled\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures = []\n",
    "splits = fastai.tabular.all.RandomSplitter(\n",
    "    valid_pct=0.2, seed=42)(fastai.tabular.all.range_of(full))\n",
    "\n",
    "cont = ['esi', 'age']\n",
    "cat = [\n",
    "    'gender',\n",
    "    'ethnicity',\n",
    "    'race',\n",
    "    'lang',\n",
    "    'religion',\n",
    "    'maritalstatus',\n",
    "    'employstatus',\n",
    "    'insurance_status',\n",
    "    'disposition',\n",
    "    'arrivalmode',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cat` and `cont` are the *categorical* and the *continuous* variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = fastai.tabular.all.TabularPandas(\n",
    "    df=full,\n",
    "    procs=procedures,\n",
    "    cat_names=cat,\n",
    "    cont_names=cont,\n",
    "    y_names='previousdispo',\n",
    "    splits=splits\n",
    ")\n",
    "to.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = to.train.xs, to.train.y\n",
    "X_test, y_test = to.valid.xs, to.valid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(300, verbose=2, n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, preds, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "plot_labels = list(full['previousdispo'].unique())\n",
    "plot_labels.sort()\n",
    "plot_labels_transformed = transformers['previousdispo'].inverse_transform(plot_labels)\n",
    "class_names = list(plot_labels_transformed)\n",
    "tick_marks = np.arange(len(class_names)) + 0.5\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=90)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a hard time predicting `LWBS before Triage` and `Observation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth= 5000)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, preds, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "plot_labels = list(full['previousdispo'].unique())\n",
    "plot_labels.sort()\n",
    "plot_labels_transformed = transformers['previousdispo'].inverse_transform(plot_labels)\n",
    "class_names = list(plot_labels_transformed)\n",
    "tick_marks = np.arange(len(class_names)) + 0.5\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=90)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Decision Tree Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a hard time predicting `LWBS before Triage` and `Observation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(500, verbose=2, n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, preds, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "plot_labels = list(full['previousdispo'].unique())\n",
    "plot_labels.sort()\n",
    "plot_labels_transformed = transformers['previousdispo'].inverse_transform(plot_labels)\n",
    "class_names = list(plot_labels_transformed)\n",
    "tick_marks = np.arange(len(class_names)) + 0.5\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=90)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are less than encouraging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisors of `1827162` are `1, 2, 3, 6, 9, 18, 83, 166, 249, 498, 747, 1223, 1494, 2446, 3669, 7338, 11007, 22014, 101509, 203018, 304527, 609054, 913581, 1827162`. [Divisors Calculator](https://www.hackmath.net/en/calculator/divisors?n=1827162&submit=Calculate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1494\n",
    "\n",
    "X_train_batches = [X_train[x : x + batch_size] for x in range(0, len(X_train), batch_size)]\n",
    "y_train_batches = [y_train[x : x + batch_size] for x in range(0, len(y_train), batch_size)]\n",
    "\n",
    "X_train_batches = np.array(X_train_batches)\n",
    "y_train_batches = np.array(y_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batches.shape, y_train_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(800, n_jobs=-1)\n",
    "batched_data = list(zip(X_train_batches, y_train_batches))\n",
    "\n",
    "counter = 1\n",
    "for i, j in batched_data:\n",
    "    model.fit(i, j)\n",
    "    print(f'Done with batch {counter} of {len(batched_data)}')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, preds, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "plot_labels = list(full['previousdispo'].unique())\n",
    "plot_labels.sort()\n",
    "plot_labels_transformed = transformers['previousdispo'].inverse_transform(plot_labels)\n",
    "class_names = list(plot_labels_transformed)\n",
    "tick_marks = np.arange(len(class_names)) + 0.5\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=90)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential problem with the current state of this notebook is that the validation data is also repeated, or generated by the oversampling algorithm, which might be a problem for determining the accuracy.  \n",
    "\n",
    "In addition, many of the models have a hard time predicting `LWBS before Triage` and `Observation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenda\n",
    "1. Attempt incorporating Shap Values so we can see the specific datapoints that influence disposition of patient the most\n",
    "2. Find other way to balance the data that won't lead to lots of repeated data.\n",
    "Last Priority:\n",
    "3. Attempt incorporating PCA - dimensionality-reducing model to identify important columns\n",
    "4. Use other machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Values implmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "To increase overall model transparency and pinpoint specific metrics that have the largest weight on classification output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_test\u001b[49m, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\") \n",
    "model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'X_test', 'y_test' used to save time with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first plot comparing importance of different metrics\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Classification using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = tf.keras.Sequential([tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.SGD(), metrics = ['accuracy'])\n",
    "class_model.fit(X_train, y_train, epochs = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model.evaluate(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "026d1ead030e2e4612b002316f6686612805c52872ab262749162caf603f666c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
